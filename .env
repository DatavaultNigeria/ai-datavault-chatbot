import streamlit as st
import pandas as pd
import sqlite3
import sqlalchemy
from sqlalchemy import create_engine, text, inspect
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import re
import io
import warnings
warnings.filterwarnings('ignore')

# For AI-powered query generation
from openai import OpenAI
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()

class DatabaseChatbot:
    def __init__(self):
        self.engine = None
        self.connection = None
        self.df = None
        self.table_schemas = {}
        self.data_source_type = None
        
        # Initialize AI client
        self.setup_ai_client()
    
    def setup_ai_client(self):
        """Setup AI client for natural language processing."""
        # Debug environment loading first
        st.write("üîç **Debug Info:**")
        
        # Check if .env file exists
        env_file_exists = os.path.exists('.env')
        st.write(f"- .env file exists: {env_file_exists}")
        
        # Try to read .env file directly
        if env_file_exists:
            try:
                with open('.env', 'r') as f:
                    env_content = f.read()
                st.write(f"- .env file content length: {len(env_content)} characters")
                # Show if GROQ_API_KEY is in the file (without showing the actual key)
                has_groq_key = 'GROQ_API_KEY' in env_content
                st.write(f"- Contains GROQ_API_KEY: {has_groq_key}")
            except Exception as e:
                st.write(f"- Error reading .env file: {e}")
        
        # Check environment variables
        groq_key = os.getenv("GROQ_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        
        st.write(f"- GROQ_API_KEY loaded: {groq_key is not None}")
        if groq_key:
            st.write(f"- GROQ_API_KEY length: {len(groq_key)} chars")
            st.write(f"- GROQ_API_KEY first 10 chars: {groq_key[:10]}...")
            # Check for common issues
            if groq_key.startswith('"') or groq_key.startswith("'"):
                st.error("‚ùå API key has quotes - remove them from .env file")
            if ' ' in groq_key:
                st.error("‚ùå API key contains spaces - check .env file formatting")
        
        st.write(f"- OPENAI_API_KEY loaded: {openai_key is not None}")
        
        api_key = groq_key or openai_key
        
        if not api_key:
            st.error("‚ùå No API key found. Please check your .env file contains:")
            st.code("GROQ_API_KEY=your_key_here")
            st.write("Make sure there are no quotes, spaces, or extra characters.")
            self.client = None
            return
        
        # Check if API key looks valid (basic validation)
        if len(api_key.strip()) < 20:
            st.error(f"‚ùå API key appears to be invalid (too short: {len(api_key)} chars)")
            self.client = None
            return
        
        try:
            if groq_key:
                st.write("üîß Attempting to initialize Groq client...")
                
                # Clean the API key
                clean_key = api_key.strip().strip('"').strip("'")
                
                self.client = OpenAI(
                    api_key=clean_key,
                    base_url="https://api.groq.com/openai/v1",
                )
                self.model = "llama3-70b-8192"
                
                # Test the connection with a simple call
                st.write("üß™ Testing API connection...")
                test_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": "Hello"}],
                    max_tokens=5
                )
                st.success("‚úÖ Groq client initialized and tested successfully!")
                
            else:
                st.write("üîß Attempting to initialize OpenAI client...")
                self.client = OpenAI(api_key=api_key.strip())
                self.model = "gpt-3.5-turbo"
                st.success("‚úÖ OpenAI client initialized successfully!")
                
        except Exception as e:
            st.error(f"‚ùå Failed to initialize AI client: {e}")
            st.error(f"Error type: {type(e).__name__}")
            st.write("**Troubleshooting steps:**")
            st.write("1. Check that your GROQ_API_KEY is valid and active")
            st.write("2. Make sure .env file is in the same directory as your script")
            st.write("3. Restart your Streamlit app after changing .env")
            st.write("4. Try copying your API key again from Groq console")
            self.client = None
    
    def connect_to_database(self, connection_string, db_type="sqlite"):
        """Connect to various database types."""
        try:
            if db_type == "sqlite":
                self.engine = create_engine(f"sqlite:///{connection_string}")
            elif db_type == "mysql":
                self.engine = create_engine(f"mysql+pymysql://{connection_string}")
            elif db_type == "postgresql":
                self.engine = create_engine(f"postgresql://{connection_string}")
            elif db_type == "sql_server":
                self.engine = create_engine(f"mssql+pyodbc://{connection_string}")
            
            self.connection = self.engine.connect()
            self.data_source_type = "database"
            self.load_table_schemas()
            return True
            
        except Exception as e:
            st.error(f"Database connection failed: {e}")
            return False
    
    def load_file_data(self, uploaded_file):
        """Load data from uploaded files."""
        try:
            if uploaded_file.name.endswith('.csv'):
                self.df = pd.read_csv(uploaded_file)
            elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                self.df = pd.read_excel(uploaded_file)
            elif uploaded_file.name.endswith('.json'):
                self.df = pd.read_json(uploaded_file)
            
            self.data_source_type = "file"
            return True
            
        except Exception as e:
            st.error(f"File loading failed: {e}")
            return False
    
    def load_table_schemas(self):
        """Load database table schemas for context."""
        try:
            inspector = inspect(self.engine)
            tables = inspector.get_table_names()
            
            for table in tables:
                columns = inspector.get_columns(table)
                self.table_schemas[table] = {
                    'columns': [col['name'] for col in columns],
                    'types': {col['name']: str(col['type']) for col in columns}
                }
        except Exception as e:
            st.warning(f"Could not load table schemas: {e}")
    
    def natural_language_to_sql(self, query, context=""):
        """Convert natural language to SQL using AI."""
        if not self.client:
            return None
        
        # Build context about available tables and columns
        schema_context = ""
        if self.table_schemas:
            schema_context = "Available tables and columns:\n"
            for table, info in self.table_schemas.items():
                schema_context += f"- {table}: {', '.join(info['columns'])}\n"
        
        prompt = f"""
        You are a SQL expert. Convert this natural language query to SQL.
        
        {schema_context}
        
        Additional context: {context}
        
        User query: "{query}"
        
        Rules:
        - Return ONLY the SQL query, no explanations
        - Use proper SQL syntax
        - Handle date formats appropriately
        - Include appropriate JOINs if multiple tables are needed
        - Use LIMIT for large datasets
        - Consider common business terms (Q1 = Jan-Mar, etc.)
        
        SQL Query:
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a SQL expert who converts natural language to SQL queries."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            sql_query = response.choices[0].message.content.strip()
            # Clean up the response
            sql_query = re.sub(r'^```sql\n?', '', sql_query, flags=re.IGNORECASE)
            sql_query = re.sub(r'\n?```$', '', sql_query)
            
            return sql_query
            
        except Exception as e:
            st.error(f"AI query generation failed: {e}")
            return None
    
    def natural_language_to_pandas(self, query):
        """Convert natural language to pandas operations for file data."""
        if not self.client or self.df is None:
            return None
        
        # Get basic info about the dataframe
        columns_info = []
        for col in self.df.columns:
            dtype = str(self.df[col].dtype)
            sample_values = self.df[col].dropna().head(3).tolist()
            columns_info.append(f"- {col} ({dtype}): {sample_values}")
        
        columns_context = "\n".join(columns_info)
        
        prompt = f"""
        You are a pandas expert. Convert this natural language query to pandas code for data visualization and analysis.
        
        DataFrame info:
        Shape: {self.df.shape}
        Columns and sample data:
        {columns_context}
        
        User query: "{query}"
        
        Rules:
        - Use 'df' as the dataframe variable
        - For plots, use st.pyplot() or st.plotly_chart() to display them in Streamlit
        - For categorical variables, use bar plots or count plots
        - For numerical variables, use histograms or box plots
        - Include proper titles and labels
        - Handle multiple plots by creating subplots or separate plots
        - Return executable code that creates visualizations
        - Use matplotlib/seaborn with st.pyplot() or plotly with st.plotly_chart()
        
        Example for plotting:
        ```python
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots()
        df['column'].hist(ax=ax)
        ax.set_title('Histogram of Column')
        st.pyplot(fig)
        ```
        
        Pandas/Plotting Code:
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a pandas expert who converts natural language to pandas code."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            pandas_code = response.choices[0].message.content.strip()
            # Clean up the response
            pandas_code = re.sub(r'^```python\n?', '', pandas_code, flags=re.IGNORECASE)
            pandas_code = re.sub(r'\n?```$', '', pandas_code)
            
            return pandas_code
            
        except Exception as e:
            st.error(f"AI pandas code generation failed: {e}")
            return None
    
    def execute_sql_query(self, sql_query):
        """Execute SQL query and return results."""
        try:
            result_df = pd.read_sql(sql_query, self.connection)
            return result_df
        except Exception as e:
            st.error(f"SQL execution failed: {e}")
            return None
    
    def execute_pandas_code(self, pandas_code):
        """Execute pandas code safely."""
        try:
            # Create safe execution environment with plotting libraries
            local_vars = {
                'df': self.df.copy(), 
                'pd': pd, 
                'np': np, 
                'plt': plt, 
                'sns': sns,
                'st': st
            }
            
            # Execute the code
            exec(pandas_code, {'__builtins__': {}}, local_vars)
            
            # Check if this was a plotting operation
            if any(keyword in pandas_code.lower() for keyword in ['plot', 'hist', 'bar', 'scatter', 'plt.', 'sns.', 'st.pyplot']):
                # For plotting operations, return the original dataframe to show it worked
                return self.df
            
            # Try to find a result variable (new DataFrame)
            for var_name, var_value in local_vars.items():
                if var_name not in ['df', 'pd', 'np', 'plt', 'sns', 'st'] and isinstance(var_value, pd.DataFrame):
                    return var_value
            
            # If no new DataFrame found, return the modified df
            return local_vars['df']
            
        except Exception as e:
            st.error(f"Pandas code execution failed: {e}")
            st.error(f"Generated code: {pandas_code}")
            return None
    
    def generate_insights(self, df, original_query):
        """Generate insights and recommendations from the data."""
        if not self.client or df is None or df.empty:
            return "No insights available."
        
        # Get basic stats about the result
        stats_info = f"""
        Result shape: {df.shape}
        Columns: {list(df.columns)}
        Data types: {df.dtypes.to_dict()}
        """
        
        if len(df) <= 10:
            sample_data = df.to_dict('records')
        else:
            sample_data = df.head(5).to_dict('records')
        
        prompt = f"""
        Analyze this data result and provide business insights and recommendations.
        
        Original query: "{original_query}"
        
        Data info:
        {stats_info}
        
        Sample data:
        {sample_data}
        
        Please provide:
        1. Key insights from the data
        2. Notable patterns or trends
        3. Business recommendations
        4. Potential areas for further analysis
        
        Keep it concise and business-focused.
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a business analyst who provides insights from data."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"Could not generate insights: {e}"
    
    def create_visualizations(self, df, query):
        """Create appropriate visualizations based on the data."""
        if df is None or df.empty:
            st.warning("No data to visualize")
            return
        
        # Determine best visualization based on data types and shape
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
        
        # Convert date-like strings to datetime
        for col in df.columns:
            if df[col].dtype == 'object':
                try:
                    pd.to_datetime(df[col])
                    date_cols.append(col)
                except:
                    pass
        
        st.subheader("üìä Visualizations")
        
        # Create visualizations based on data structure
        if len(df) == 1:
            # Single row - show key metrics
            st.metric("Result", df.iloc[0, 0] if len(df.columns) == 1 else f"{len(df.columns)} metrics")
            
        elif len(numeric_cols) >= 2:
            # Scatter plot for numeric data
            fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1], 
                           title=f"{numeric_cols[0]} vs {numeric_cols[1]}")
            st.plotly_chart(fig, use_container_width=True)
            
        elif len(numeric_cols) == 1 and len(categorical_cols) >= 1:
            # Bar chart
            fig = px.bar(df, x=categorical_cols[0], y=numeric_cols[0],
                        title=f"{numeric_cols[0]} by {categorical_cols[0]}")
            st.plotly_chart(fig, use_container_width=True)
            
        elif len(date_cols) >= 1 and len(numeric_cols) >= 1:
            # Time series
            fig = px.line(df, x=date_cols[0], y=numeric_cols[0],
                         title=f"{numeric_cols[0]} over time")
            st.plotly_chart(fig, use_container_width=True)
            
        elif len(categorical_cols) >= 1:
            # Value counts
            value_counts = df[categorical_cols[0]].value_counts().head(10)
            fig = px.bar(x=value_counts.index, y=value_counts.values,
                        title=f"Distribution of {categorical_cols[0]}")
            st.plotly_chart(fig, use_container_width=True)
        
        # Always show a data table
        st.subheader("üìã Data Table")
        st.dataframe(df, use_container_width=True)

# Initialize the chatbot
@st.cache_resource
def get_chatbot():
    return DatabaseChatbot()

# Streamlit App
st.set_page_config(
    page_title="Database Chatbot",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ Natural Language Database Chatbot")
st.markdown("Connect to databases or upload files, then ask questions in plain English!")

# Initialize chatbot
chatbot = get_chatbot()

# Sidebar for connections
with st.sidebar:
    st.header("üîå Data Connection")
    
    connection_type = st.radio(
        "Choose data source:",
        ["Upload File", "SQLite Database", "MySQL", "PostgreSQL", "SQL Server"]
    )
    
    if connection_type == "Upload File":
        uploaded_file = st.file_uploader(
            "Upload your data file",
            type=['csv', 'xlsx', 'xls', 'json']
        )
        
        if uploaded_file:
            if chatbot.load_file_data(uploaded_file):
                st.success("‚úÖ File loaded successfully!")
                st.write(f"Shape: {chatbot.df.shape}")
                st.write(f"Columns: {list(chatbot.df.columns)}")
    
    else:
        st.text_input(
            "Connection String",
            help="Enter your database connection string",
            key="conn_string"
        )
        
        if st.button("Connect"):
            conn_string = st.session_state.conn_string
            db_type = connection_type.lower().replace(" ", "_")
            
            if chatbot.connect_to_database(conn_string, db_type):
                st.success("‚úÖ Connected to database!")
                if chatbot.table_schemas:
                    st.write("Available tables:")
                    for table in chatbot.table_schemas.keys():
                        st.write(f"- {table}")

# Main interface
if chatbot.data_source_type:
    st.header("üí¨ Ask Your Question")
    
    # Show AI status
    if not chatbot.client:
        st.warning("‚ö†Ô∏è AI query generation not available. You can still write SQL/Python code manually.")
    
    # Example queries
    with st.expander("üí° Example Queries"):
        if chatbot.data_source_type == "database":
            st.markdown("""
            **Natural Language (requires AI):**
            - Show me total sales for Q1 2024
            - What are the top 10 customers by revenue?
            - Compare monthly sales trends
            
            **Direct SQL:**
            - SELECT * FROM sales WHERE date >= '2024-01-01'
            - SELECT customer, SUM(revenue) FROM orders GROUP BY customer
            """)
        else:
            st.markdown("""
            **Natural Language (requires AI):**
            - Show me the top 10 values in [column name]
            - What's the average [column name] by [category]?
            - Plot histograms for numerical columns
            
            **Direct Python/Pandas:**
            - df.describe()
            - df.groupby('category').mean()
            - df.hist(); st.pyplot()
            """)
    
    # Query input
    query_type = st.radio("Query Type:", 
                         ["Natural Language", "Direct Code"] if chatbot.client 
                         else ["Direct Code"])
    
    if query_type == "Natural Language":
        user_query = st.text_area(
            "Enter your question in natural language:",
            placeholder="e.g., 'Show me sales trends for Q1'",
            height=100
        )
    else:
        if chatbot.data_source_type == "database":
            user_query = st.text_area(
                "Enter SQL query:",
                placeholder="SELECT * FROM table_name LIMIT 10",
                height=100
            )
        else:
            user_query = st.text_area(
                "Enter Python/Pandas code:",
                placeholder="df.describe()",
                height=100
            )
    
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("üîç Analyze", type="primary"):
            if user_query:
                with st.spinner("ü§ñ Processing your request..."):
                    
                    # Generate and execute query
                    if chatbot.data_source_type == "database":
                        if query_type == "Natural Language" and chatbot.client:
                            sql_query = chatbot.natural_language_to_sql(user_query)
                        else:
                            sql_query = user_query  # Direct SQL
                            
                        if sql_query:
                            st.subheader("üîß SQL Query")
                            st.code(sql_query, language="sql")
                            
                            result_df = chatbot.execute_sql_query(sql_query)
                        else:
                            result_df = None
                    
                    else:  # File data
                        if query_type == "Natural Language" and chatbot.client:
                            pandas_code = chatbot.natural_language_to_pandas(user_query)
                        else:
                            pandas_code = user_query  # Direct pandas code
                            
                        if pandas_code:
                            st.subheader("üîß Generated Code")
                            st.code(pandas_code, language="python")
                            
                            result_df = chatbot.execute_pandas_code(pandas_code)
                        else:
                            result_df = None
                    
                    # Display results
                    if result_df is not None:
                        # For plotting operations, the visualizations are already shown
                        if pandas_code and any(keyword in pandas_code.lower() for keyword in ['plot', 'hist', 'bar', 'scatter', 'plt.', 'sns.', 'st.pyplot']):
                            st.success("‚úÖ Visualizations created successfully!")
                        
                        # Only show additional visualizations if it's not already a plotting operation
                        elif not result_df.empty:
                            # Create visualizations
                            chatbot.create_visualizations(result_df, user_query)
                        
                        # Generate insights for non-empty results
                        if not result_df.empty and chatbot.client:
                            insights = chatbot.generate_insights(result_df, user_query)
                            if insights:
                                st.subheader("üí° AI Insights & Recommendations")
                                st.write(insights)
                    
                    else:
                        st.warning("No results found or query execution failed.")
            else:
                st.warning("Please enter a question.")

else:
    st.info("üëÜ Please connect to a data source using the sidebar to get started.")
    
    # Demo section
    st.header("üöÄ Features")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("üóÑÔ∏è Multiple Data Sources")
        st.write("Connect to SQL databases, upload Excel/CSV files, or use JSON data")
    
    with col2:
        st.subheader("üó£Ô∏è Natural Language")
        st.write("Ask questions in plain English - no SQL knowledge required")
    
    with col3:
        st.subheader("üìä Smart Analysis")
        st.write("Get visualizations, insights, and recommendations automatically")

# Footer
st.markdown("---")
st.markdown("ü§ñ Powered by AI | Built with Streamlit")